#!/usr/bin/env python
import argparse
import getpass
import hashlib
import httplib
import json
import os
import sys
import time
import urllib2
import urlparse
import re
import cPickle
import zipfile
import tempfile
import urllib
from functools import wraps

MAINTENANCE_NOTICE_URL = "http://fsurf.ci-connect.net/maintenance.txt"
UPDATE_NOTICE_URL = "http://fsurf.ci-connect.net/update.json"
REST_ENDPOINT = "http://fsurf.ci-connect.net/freesurfer"
VERSION = '2.0.41'
CREDENTIAL_FILE = os.path.expanduser('~/.fsurf/credentials')
# supported versions of FreeSurfer
FREESURFER_VERSIONS = ['5.1.0', '5.3.0', '6.0.0']
VALID_EXTENSIONS = ['nii.gz',
                    'nii',
                    'mgz',
                    'mgh',
                    'mnc']


usage_text = """
%(prog)s {list|status|remove|output|retry|change-password|submit} [options]

|------------------------------------------------------------------------------
| Command       | Function       | Required Switches    | Optional Switches
|---------------|----------------|----------------------|---------------------
| submit        | Upload and     | --subject='[subject]'| --help
|               | process scan   |                      | --user='[user name]'
|               |                |                      | --input='[path]'
|               |                |                      | --dualcore
|               |                |                      | --defaced
|               |                |                      | --deidentified
|               |                |                      | --freesurfer-options='[options]'
|---------------|----------------|----------------------|---------------------
| list          | List workflows |                      | --help
|               |                |                      | --user='[user name]'
|               |                |                      | --all-workflows
|---------------|----------------|----------------------|---------------------
| status        | Get workflow   | --id='[workflow id]' | --help
|               | status         |                      | --user='[user name]'
|---------------|----------------|----------------------|---------------------
| output        | Get output     | --id='[workflow id]' | --help
|               | from completed |                      | --user='[user name]'
|               | workflow       |                      | --log-only
|---------------|----------------|----------------------|---------------------
| retry         | Retry a failed | --id='[workflow id]' | --help
|               | workflow       |                      | --user='[user name]'
|---------------|----------------|----------------------|---------------------
| remove        | Remove         | --id='[workflow id]' | --help
|               | workflow       |                      | --user='[user name]'
|---------------|----------------|----------------------|---------------------
|change-password| Change account |                      | --help
|               | password       |                      | --user='[user name]'
|------------------------------------------------------------------------------

See https://support.opensciencegrid.org/solution/folders/12000002373 for more
help
"""


def protect(f):
    """
    Decorator to protect a function in a try/except block

    :param f: function to protect
    :return:
    """
    @wraps(f)
    def wrapped(*args, **kwargs):
        try:
            return f(*args, **kwargs)
        except Exception:
            error_message('Unexpected error occurred')
            sys.exit(1)
    return wrapped


def check_maintenance(f):
    """
    Decorator around user functions to check for a maintenance
    message and display it if present
    
    :param f: 
    :return: 
    """
    @wraps(f)
    def wrapped(*args, **kwargs):
        maintenance_mesg = get_maintenance_notice()
        if maintenance_mesg:
            sys.stdout.write(maintenance_mesg)
            sys.exit(0)
        return f(*args, **kwargs)
    return wrapped


def check_update(f):
    """
    Decorator around user functions to check for an update message 
    and display it if present and for a more recent version

    :param f: 
    :return: 
    """

    @wraps(f)
    def wrapped(*args, **kwargs):
        update_info = json.loads(get_update_notice())
        if update_info['version'] > VERSION:
            sys.stdout.write("---- New fsurf version available ---\n")
            sys.stdout.write(update_info['mesg'] + "\n")
        return f(*args, **kwargs)

    return wrapped


def error_message(message):
    """
    Print an error message with default message

    :param message: error message to write
    :return: None
    """
    sys.stderr.write("{0}\n".format(message))
    sys.stderr.write("\n\nIf you continue to have problems, please go " +
                     "to http://support.opensciencegrid.org/ and open a \n" +
                     "support ticket indicating that you're running fsurf " +
                     "version {0}, give your username, \n".format(VERSION) +
                     "and a description of the issue.\n")


def format_seconds(duration, max_comp=2):
    """
    Utility for converting time to a readable format

    :param duration: time in seconds and miliseconds
    :param max_comp: number of components of the returned time
    :return: time in n component format
    """
    comp = 0
    if duration is None:
        return '-'
    # milliseconds = math.modf(duration)[0]
    sec = int(duration)
    formatted_duration = ''
    years = sec / 31536000
    sec -= 31536000 * years
    days = sec / 86400
    sec -= 86400 * days
    hrs = sec / 3600
    sec -= 3600 * hrs
    mins = sec / 60
    sec -= 60 * mins

    # years
    if comp < max_comp and (years >= 1 or comp > 0):
        comp += 1
        if days == 1:
            formatted_duration += str(years) + ' year, '
        else:
            formatted_duration += str(years) + ' years, '

    # days
    if comp < max_comp and (days >= 1 or comp > 0):
        comp += 1
        if days == 1:
            formatted_duration += str(days) + ' day, '
        else:
            formatted_duration += str(days) + ' days, '

    # hours
    if comp < max_comp and (hrs >= 1 or comp > 0):
        comp += 1
        if hrs == 1:
            formatted_duration += str(hrs) + ' hr, '
        else:
            formatted_duration += str(hrs) + ' hrs, '

    # mins
    if comp < max_comp and (mins >= 1 or comp > 0):
        comp += 1
        if mins == 1:
            formatted_duration += str(mins) + ' min, '
        else:
            formatted_duration += str(mins) + ' mins, '

    # seconds
    if comp < max_comp and (sec >= 1 or comp > 0):
        comp += 1
        if sec == 1:
            formatted_duration += str(sec) + " sec, "
        else:
            formatted_duration += str(sec) + " secs, "

    if formatted_duration[-2:] == ", ":
        formatted_duration = formatted_duration[:-2]

    return formatted_duration


def get_user_credentials():
    """
    Try to get user credentials from a file

    :return: username, password
    """
    if os.path.isfile(CREDENTIAL_FILE):
        with open(CREDENTIAL_FILE, 'rb') as f:
            try:
                pickle = cPickle.load(f)
                if type(pickle) == dict:
                    username = pickle['username']
                    password = pickle['password']
                    return username, password
                else:
                    sys.stdout.write("Credential file is invalid\n")
            except EOFError:
                sys.stdout.write("Credential file is invalid\n")
    return None, None


def save_user_credentials(username, password):
    """
    Try to save user credentials to a file

    :return: None
    """
    if get_user_response('Save credentials? '):
        try:
            cred_dict = {'username': username,
                         'password': password}
            cred_dir = os.path.dirname(CREDENTIAL_FILE)
            if not os.path.exists(cred_dir):
                os.mkdir(cred_dir)
            with open(CREDENTIAL_FILE, 'wb') as f:
                cPickle.dump(cred_dict, f, cPickle.HIGHEST_PROTOCOL)
        except OSError:
            sys.stdout.write("Can't save credentials to {0}\n".format(CREDENTIAL_FILE))
    return


def get_user_info(args):
    """
    Query user for username and password and return

    :param args: argparse object
    :return: username, password
    """
    if not args.user:
        username, password = get_user_credentials()
        if username and password:
            return username, password

    if args.user:
        username = args.user
    else:
        username = raw_input("Enter username: ").strip()

    password = getpass.getpass("Enter password: ")
    save_user_credentials(username, password)
    return username.strip(), password


def get_user_response(prompt, default=None):
    """
    Give a prompt to the user and return a True/False based on user input

    :param prompt: Text to present to user
    :param default: Text to use if user enters a blank response
    :return: True if user said yes, False otherwise
    """
    response = ""
    while response not in ['y', 'n', 'yes', 'no']:
        response = raw_input(prompt)
        response = response.strip().lower()
        if response == "":
            response = default

    if response in ['y', 'yes']:
        return True
    else:
        return False


def get_response(query_parameters, noun, method, endpoint=REST_ENDPOINT):
    """
    Query rest endpoint with given  string and return results

    :param endpoint: url to REST endpoint
    :param query_parameters: a dictionary with key, values parameters
    :param noun: object being worked on
    :param method:  HTTP method that should be used
    :return: (status code, response from query)
    """
    url = "{0}/{2}?{1}".format(endpoint,
                               urllib.urlencode(query_parameters),
                               noun)
    parsed = urlparse.urlparse(url)
    try:
        conn = httplib.HTTPConnection(parsed.netloc)
        if method == 'PUT':
            conn.request(method,
                         "{0}?{1}".format(parsed.path, parsed.query),
                         body=None,
                         headers={'Content-Length': 0})
        else:
            conn.request(method, "{0}?{1}".format(parsed.path, parsed.query))
        resp = conn.getresponse()
        return resp.status, resp.read()
    except IOError as e:  # mainly dns errors
        response = {'status': 500,
                    'result': str(e)}
        return 500, json.dumps(response)
    except httplib.HTTPException as e:
        response = {'status': 400,
                    'result': str(e)}
        return 400, json.dumps(response)


def download_output(query_parameters, noun, endpoint=REST_ENDPOINT):
    """
    Query rest endpoint with given  string and return results

    :param endpoint: url to REST endpoint
    :param query_parameters: a dictionary with key, values parameters
    :param noun: object being worked on
    :return: (status code, response from query)
    """
    url = "{0}/{2}?{1}".format(endpoint,
                               urllib.urlencode(query_parameters),
                               noun)
    parsed = urlparse.urlparse(url)
    try:
        conn = httplib.HTTPConnection(parsed.hostname)
        conn.request('GET', "{0}?{1}".format(parsed.path, parsed.query))
        resp = conn.getresponse()
        content_type = resp.getheader('content-type')
        if content_type.startswith('application/x-bzip2') and \
           content_type.startswith('text/plain'):
            return resp.status, resp.read()
        content_disposition = resp.getheader('content-disposition')
        if content_type.startswith('application/x-bzip2'):
            filename = 'fsurf_output.tar.bz2'
        elif content_type.startswith('text/plain'):
            filename = 'recon-all.log'
        elif content_type.startswith('application/json'):
            return resp.status, resp.read()
        else:
            response = {'status': 500,
                        'result': "Unknown content-type: "
                                  "{0}".format(content_type)}
            return 500, json.dumps(response)
        match_obj = re.search(r'filename=(.*)', content_disposition)
        if match_obj:
            filename = match_obj.group(1)
        with open(filename, 'wb') as f:
            temp = resp.read(4096)
            while temp:
                f.write(temp)
                temp = resp.read(4096)
        return resp.status, json.dumps({'status': 200,
                                        'result': "output downloaded",
                                        'filename': filename})
    except httplib.HTTPException as e:
        response = {'status': 400,
                    'result': str(e)}
        return 400, json.dumps(response)


def encode_file(body, filename):
    """
    Encode a file in a binary form and return a mime content type
    and encoded binary data

    :param body: binary data to encode
    :param filename: name of file with data to encode
    :return: content_type, body
    """
    boundary = '--------------MIME_Content_Boundary---------------'
    lines = []
    lines.append('--' + boundary)
    lines.append('Content-Disposition: form-data; name="input_file"; '
                 'filename="{0}"'.format(filename))
    lines.append('Content-Type: application/octet-stream')
    lines.append('')
    lines.append(body)
    lines.append('--' + boundary + '--')
    lines.append('')
    encoded = "\r\n".join(lines)
    content_type = 'multipart/form-data; boundary=%s' % boundary
    return content_type, encoded


def zip_directory(zip_obj, directory):
    """
    Recursively walk through a directory and add files to zipfile
    object given

    :param zip_obj:  a ZipFile instance that will be populated
    :param directory: path to directory
    :return: True if successful, False otherwise
    """
    success = True
    cur_dir = os.getcwd()
    try:
        base_path = os.path.dirname(directory)
        os.chdir(base_path)
        subject_dir = os.path.basename(directory)
        for root, dirs, files in os.walk(subject_dir):
            for entry in dirs:
                zip_obj.write(os.path.join(root, entry))
            for entry in files:
                zip_obj.write(os.path.join(root, entry))
        zip_obj.close()
    except OSError:
        success = False
    finally:
        os.chdir(cur_dir)
    return success


def upload_item(query_parameters, noun, filename, body, method, endpoint=REST_ENDPOINT):
    """
    Issue a POST request to given endpoint

    :param endpoint: url to REST endpoint
    :param query_parameters: a dictionary with key, values parameters
    :param noun: object being worked on
    :param filename: name of file being transferred
    :param body:  data to be sent in the body
    :param method:  HTTP method that should be used (POST, PUT)
    :return: (status code, response from query)
    """
    url = "{0}/{2}?{1}".format(endpoint,
                               urllib.urlencode(query_parameters),
                               noun)
    parsed = urlparse.urlparse(url)
    try:
        conn = httplib.HTTPConnection(parsed.hostname)
        content_type, body = encode_file(body, filename)
        headers = {'content-type': content_type,
                   'Accept': 'text/plain'}
        conn.request(method,
                     "{0}?{1}".format(parsed.path, parsed.query),
                     body,
                     headers)
        resp = conn.getresponse()
        if resp.status == 401:
            # invalid password
            response = {'status': resp.status,
                        'result': 'Invalid username/password'}
            return resp.status, json.dumps(response)
        elif resp.status == 400:
            # invalid password
            response = {'status': resp.status,
                        'result': 'Invalid parameter'}
            return resp.status, json.dumps(response)

        return resp.status, resp.read()
    except httplib.HTTPException as e:
        response = {'status': 400,
                    'result': str(e)}
        return 400, json.dumps(response)


def get_token(userid, password):
    """
    Generate an authentication token and timestamp
    :param userid: user id identifying account
    :param password: password for user account
    :return: timestamp, token
    """
    parameters = {'userid': userid}
    code, response = get_response(parameters, 'user/salt', 'GET', REST_ENDPOINT)
    if code == 401:
        error_message("User account disabled\n")
        return None, None
    elif code == 400:
        error_message("Userid not found\n")
        return None, None
    timestamp = time.time()
    response_obj = json.loads(response)
    salt = response_obj['result']
    token = hashlib.sha256(salt + password).hexdigest()
    token = hashlib.sha256(token + str(timestamp)).hexdigest()
    return str(timestamp), token


@protect
@check_maintenance
@check_update
def list_workflows(args):
    """
    List the workflows currently in the system

    :param args: parsed command line args from argparse
    :return: exits with 0 on success, 1 on error
    """
    try:
        username, password = get_user_info(args)
        timestamp, token = get_token(username, password)
        if token is None:
            return 1
        query_params = {'userid': username,
                        'timestamp': timestamp,
                        'token': token,
                        'all': args.all_workflows}
        status, response = get_response(query_params, 'job', 'GET')
        if status == 401:
            error_message("Invalid username or password")
            sys.exit(0)
        elif status != 200:
            error_message("Error getting workflow information")
            sys.exit(1)
        if args.all_workflows:
            sys.stdout.write("All workflows\n")
        else:
            sys.stdout.write("Workflows submitted in last month\n")
        response_object = json.loads(response)
        sys.stdout.write("{0:10} {1:10} {2:27} ".format('Subject',
                                                        'Workflow',
                                                        'Submit time'))
        sys.stdout.write("{0:10} {1:15} {2:10}\n".format('Cores',
                                                         'Status',
                                                         'Tasks completed'))
        if len(response_object['jobs']) == 0:
            sys.stdout.write("\nNo workflows present\n")
        for workflow in response_object['jobs']:
            job_id = workflow[0]
            subject = workflow[1]
            status = workflow[2]
            job_time = time.ctime(workflow[3])
            if not workflow[4]:
                cores = 2
            else:
                cores = 8
            progress = workflow[5]

            sys.stdout.write("{0:10} {1:<10} {2:<27} ".format(subject,
                                                              job_id,
                                                              job_time))
            sys.stdout.write("{0:<10} {1:<15} {2:<10}\n".format(cores,
                                                                status,
                                                                progress))
        sys.exit(0)
    except IOError:
        sys.exit(1)


@protect
@check_maintenance
@check_update
def remove_workflow(args):
    """
    Stop and remove a specified pegasus workflow

    :param args: parsed command line args from argparse
    :return: exits with 0 on success, 1 on error
    """
    username, password = get_user_info(args)
    timestamp, token = get_token(username, password)
    if token is None:
        return 1
    query_params = {'userid': username,
                    'timestamp': timestamp,
                    'token': token,
                    'jobid': args.workflow_id}
    status, response = get_response(query_params, 'job', 'DELETE')
    resp_dict = json.loads(response)
    if status != 200:
        error_message("Error deleting workflow:\n" +
                      resp_dict['result'])
        return 1
    sys.stdout.write("Workflow removed\n")
    return 0


@protect
@check_maintenance
@check_update
def retry_workflow(args):
    """
    Retry a failed pegasus workflow

    :param args: parsed command line args from argparse
    :return: exits with 0 on success, 1 on error
    """
    username, password = get_user_info(args)
    timestamp, token = get_token(username, password)
    if token is None:
        return 1
    query_params = {'userid': username,
                    'timestamp': timestamp,
                    'token': token,
                    'jobid': args.workflow_id}
    status, response = get_response(query_params, 'job/retry', 'PUT')
    resp_dict = json.loads(response)
    if status != 200:
        error_message("Error retrying workflow:\n" +
                      resp_dict['result'])
        return 1
    sys.stdout.write("Workflow requeued\n")
    return 0


def validate_inputs(inputs=None, options=None):
    """
    Validate input files or subject dir and make sure that they are present
    and valid files

    :param inputs: a list of paths to files to use as input
    :param options:       args.options
    :return:              True if inputs are valid, False otherwise
    """
    valid = True
    for input_path in [os.path.abspath(os.path.expanduser(x)) for x in inputs]:
        fields = input_path.split('.')
        if len(fields) == 2:
            extension = fields[1].lower()
        elif len(fields) > 2:
            extension = ".".join(fields[-2:]).lower()
        elif os.path.isdir(input_path):
            extension = None
        elif options:
            # subject dir or input not specified correctly
            extension = None
        else:
            return False

        if extension == 'zip' or os.path.isdir(input_path):
            if not options:
                # handle cases with custom workflows not being specified
                # properly
                if extension == 'zip':
                    sys.stderr.write("Zipfile used as input without "
                                     "--freesurfer-options, exiting.\n")
                else:
                    sys.stderr.write("Directory used as input without "
                                     "--freesurfer-options, exiting.\n")
                return False

            if len(inputs) > 1:
                sys.stderr.write("Custom workflows can only have a single input, "
                                 "exiting.\n")
                return False
            if extension == 'zip' and not os.path.isfile(input_path):
                    sys.stderr.write("{0} is not present and is needed, exiting.\n".format(input_path))
                    return False
            return True
        if options:
            sys.stderr.write("Must provide a subject directory or a zip file "
                             "of subject directory for custom workflows.\n")
            return False

        if extension not in VALID_EXTENSIONS:
            # allow submission to continue after warning
            sys.stderr.write("Extension not recognized, this workflow "
                             "may fail.\n")
        if not os.path.isfile(input_path):
            sys.stderr.write("{0} is not present and is needed, exiting.\n".format(input_path))
            valid = False

    return valid


def send_file(send_params, filename, body):
    """
    Upload a file with retry and parameters

    :param send_params: parameters to use when uploading
    :param filename: name of file being uploaded
    :param body: binary data to upload
    :return: True on success, False otherwise
    """
    attempts = 1
    while attempts < 6:

        status, response = upload_item(send_params,
                                       'job/input',
                                       filename,
                                       body,
                                       'POST')
        if status == 200:
            sys.stdout.write("Uploaded {0} successfully\n".format(filename))
            return True
        response_obj = json.loads(response)
        sys.stdout.write("Error while uploading {0}\n".format(filename))
        sys.stdout.write("Error: {0}\n".format(response_obj['result']))
        sys.stdout.write("Retrying upload, attempt {0}/5\n".format(attempts))
        attempts += 1

    return False


@protect
@check_maintenance
@check_update
def submit_workflow(args):
    """
    Submit a workflow to OSG for processing

    :param args: parsed command line args from argparse
    :return: exits with 0 on success, 1 on error
    """
    if args.subject is None:
        sys.stdout.write("Subject name is missing, exiting...\n")
        sys.exit(1)

    if not validate_inputs(args.input_file, args.options):
        sys.stderr.write("Inputs not specified correctly or missing.\n")
        sys.exit(1)

    if not args.deidentified:
        agree = get_user_response("Has the MRI data been deidentified "
                                  "(This is required) (y/n)? ")
        if not agree:
            sys.stdout.write("MRI data must be deidentified, please "
                             "deidentify the data before submitting\n")
            sys.exit(1)
    if not args.defaced:
        agree = get_user_response("Has the MRI data been defaced "
                                  "(This is recommended) (y/n)? ")
        if not agree:
            sys.stdout.write("We recommend defacing MRI data\n")
            agree = get_user_response("Are you sure you want to submit this "
                                      "file (y/n)?")
            if not agree:
                sys.stdout.write("Aborting submission on user request\n")
                sys.exit(1)
    username, password = get_user_info(args)
    timestamp, token = get_token(username, password)
    num_inputs = len(args.input_file)
    if args.version not in FREESURFER_VERSIONS:
        sys.stderr.write("FreeSurfer version requested is not available!\n")
        sys.stderr.write("You requested {0}\n".format(args.version))
        sys.stderr.write("Available versions: {0}\n".format(",".join(FREESURFER_VERSIONS)))
        sys.exit(1)
    if num_inputs == 0:
        sys.stderr.write("No inputs found, refusing to submit workflow\n")
        sys.exit(1)
    query_params = {'userid': username,
                    'token': token,
                    'multicore': not bool(args.dualcore),
                    'num_inputs': num_inputs,
                    'options': args.options,
                    'version': args.version,
                    'subject': args.subject,
                    'timestamp': timestamp,
                    'jobname': "{0}_{1}".format(args.subject, timestamp)}
    if args.options:
        query_params['multicore'] = False
    sys.stdout.write("Creating and submitting workflow\n")
    status, response = get_response(query_params, 'job', 'POST')
    if status != 200:
        response_obj = json.loads(response)
        error_message("Error while creating workflow:\n" +
                      response_obj['result'])
        sys.exit(1)
    response_obj = json.loads(response)
    job_id = response_obj['job_id']
    sys.stdout.write("Workflow {0} created\n".format(job_id))

    sys.stdout.write("Uploading input files\n")
    if args.options:
        # handle custom workflows
        if os.path.isdir(args.input_file[0]):
            zip_file = tempfile.NamedTemporaryFile()
            sys.stdout.write("Creating a zip file to hold "
                             "{0}\n".format(args.input_file[0]))
            input_zip = zipfile.ZipFile(zip_file, 'w')
            sys.stdout.write("Zip file created\n")
            zip_directory(input_zip, args.input_file[0])
            input_zip.close()
            filename = "{0}_dir.zip".format(args.subject)
            zip_file.seek(0)
            body = zip_file.read()
            zip_file.close()
        else:
            input_file = os.path.abspath(os.path.expanduser(args.input_file[0]))
            filename = os.path.basename(input_file)
            with open(input_file, 'rb') as f:
                body = f.read()

        sys.stdout.write("Uploading {0}\n".format(filename))
        send_params = {'userid': username,
                       'timestamp': timestamp,
                       'token': token,
                       'jobid': job_id,
                       'filename': filename,
                       'subjectdir': True}
        if not send_file(send_params, filename, body):
            sys.stdout.write("Could not upload {0}\n".format(filename))
            sys.stdout.write("Exiting...\n")
            sys.exit(0)
        sys.exit(0)

    # standard or multiple input workflows
    file_num = 0
    for input_file in args.input_file:
        sys.stdout.write("Uploading {0} (file {1}/{2})\n".format(input_file,
                                                                 file_num + 1,
                                                                 num_inputs))
        send_params = {'userid': username,
                       'timestamp': timestamp,
                       'token': token,
                       'jobid': job_id,
                       'filename': os.path.basename(input_file),
                       'subjectdir': False}
        input_path = os.path.abspath(os.path.expanduser(input_file))
        filename = os.path.basename(input_file)
        if not os.path.isfile(input_path):
            sys.stderr.write("{0} is not present and is needed, "
                             "exiting\n".format(input_path))
            sys.exit(1)
        with open(input_path, 'rb') as f:
            body = f.read()
            if send_file(send_params, filename, body):
                file_num += 1
                continue
            else:
                sys.stdout.write("Could not upload {0}\n".format(filename))
                sys.stdout.write("Exiting...\n")
                sys.exit(1)

    sys.exit(0)


@protect
@check_maintenance
@check_update
def get_output(args):
    """
    Get output for a completed workflow

    :param args: parsed command line args from argparse
    :return: exits with 0 on success, 1 on error
    """
    username, password = get_user_info(args)
    timestamp, token = get_token(username, password)
    if token is None:
        sys.exit(1)
    query_params = {'userid': username,
                    'timestamp': timestamp,
                    'token': token,
                    'jobid': args.workflow_id}
    if args.log_only:
        sys.stdout.write("Downloading logs, this may take a while\n")
        status, response = download_output(query_params, 'job/log')
    else:
        sys.stdout.write("Downloading results, this may take a while\n")
        status, response = download_output(query_params, 'job/output')
    response_obj = json.loads(response)
    if status != 200:
        if args.log_only:
            message = "Error while downloading logs:\n"
        else:
            message = "Error while downloading results:\n"
        message += response_obj['result']
        error_message(message)
        sys.exit(1)
    sys.stdout.write("Downloaded to {0}\n".format(response_obj['filename']))
    if not args.log_only:
        sys.stdout.write("To extract the results: tar "
                         "xvjf {0}\n".format(response_obj['filename']))
    sys.exit(0)


@protect
@check_maintenance
@check_update
def get_status(args):
    """
    Get status for a workflow

    :param args: parsed command line args from argparse
    :return: exits with 0 on success, 1 on error
    """
    username, password = get_user_info(args)
    timestamp, token = get_token(username, password)
    if token is None:
        sys.exit(1)
    query_params = {'userid': username,
                    'timestamp': timestamp,
                    'token': token,
                    'jobid': args.workflow_id}
    status, response = get_response(query_params,
                                    'job/status',
                                    'GET')
    response_obj = json.loads(response)
    if status == 404:
        error_message("Workflow with id {0} not found\n".format(args.workflow_id))
        sys.exit(0)
    elif status != 200:
        error_message("Error while getting job status:\n" +
                      "{0}".format(response_obj['result']))
        sys.exit(1)

    sys.stdout.write("Workflow {0} Summary\n".format(args.workflow_id))
    if response_obj['num_inputs'] > 1:
        workflow_type = 'Multiple Input'
    elif response_obj['options'] == 'None':
        workflow_type = 'Standard'
    else:
        workflow_type = 'Custom Workflow'
    print workflow_type

    sys.stdout.write("Workflow Type: {0}\n".format(workflow_type))
    sys.stdout.write("Subject: {0}\n".format(response_obj['subject']))
    if workflow_type == 'Custom Workflow':
        sys.stdout.write("Options: {0}\n".format(response_obj['options']))
    sys.stdout.write("FreeSurfer Version: {0}\n".format(response_obj['version']))
    sys.stdout.write("Status: {0}\n".format(response_obj['job_status']))
    start_time = time.ctime(response_obj['started'])
    if response_obj['job_status'] in ['RUNNING', 'QUEUED', 'ERROR']:
        sys.stdout.write("Started: {0:<20}\n".format(start_time))
        sys.exit(0)
    start_time = time.ctime(response_obj['started'])
    end_time = time.ctime(response_obj['ended'])
    sys.stdout.write("Started: {0:<20}\n".format(start_time))
    sys.stdout.write("Ended: {0:<20}\n".format(end_time))
    cputime = format_seconds(response_obj['cputime'])
    walltime = format_seconds(response_obj['walltime'])
    sys.stdout.write("CPU Time used: {0:<20} ".format(cputime))
    sys.stdout.write("Active for: {0:<20}\n".format(walltime))
    sys.stdout.write("Completed: {0}/{1} tasks\n".format(response_obj['tasks_completed'],
                                                         response_obj['tasks']))
    if response_obj['retries'] > 0:
        sys.stdout.write("Retries: {0}\n".format(response_obj['retries']))

    sys.exit(0)

@protect
@check_maintenance
@check_update
def change_password(args):
    """
    Change the user's password

    :param args: parsed command line args from argparse
    :return: exits with 0 on success, 1 on error
    """
    username, password = get_user_info(args)
    timestamp, token = get_token(username, password)
    if token is None:
        sys.exit(1)
    new_password = getpass.getpass("Enter new password: ")
    password_confirm = getpass.getpass("Re-enter new password: ")
    if new_password != password_confirm:
        sys.stdout.write("Passwords do not match, please try again.\n")
        sys.exit(1)
    salt = hashlib.sha256(str(time.time())).hexdigest()
    pw_hash = hashlib.sha256(salt + new_password).hexdigest()

    query_params = {'userid': username,
                    'timestamp': timestamp,
                    'token': token,
                    'salt': salt,
                    'pw_hash': pw_hash}
    status, response = get_response(query_params,
                                    'user/password',
                                    'PUT')
    response_obj = json.loads(response)
    if status == 401:
        sys.stdout.write("Invalid username or password\n")
        sys.exit(1)
    elif status == 404:
        sys.stdout.write("User not found\n")
        sys.exit(1)
    elif status != 200:
        sys.stdout.write("Error while changing password:\n")
        sys.stdout.write("{0}\n".format(response_obj['result']))
        sys.exit(1)
    save_user_credentials(username, new_password)
    sys.stdout.write("{0}\n".format(response_obj['result']))
    sys.exit(0)


@protect
def get_maintenance_notice():
    """
    Check for a maintenance notice on the website and return it if present
    
    :return: string if notice present, None otherwise
    """
    try:
        result = urllib2.urlopen(MAINTENANCE_NOTICE_URL)

    except urllib2.URLError:
        return None
    if result.getcode() == 404:
        return None
    else:
        return result.read()


@protect
def get_update_notice():
    """
    Check for a update notice on the website and return it if present

    :return: string if notice present, None otherwise
    """
    try:
        result = urllib2.urlopen(UPDATE_NOTICE_URL)

    except urllib2.URLError:
        return None
    if result.getcode() == 404:
        return None
    else:
        return result.read()


def main():
    """
    Main function that parses arguments and generates the pegasus
    workflow

    :return: True if any errors occurred during DAX generaton
    """
    parser = argparse.ArgumentParser(description="Process and manage "
                                                 "freesurfer workflows",
                                     usage=usage_text)
    # General arguments
    parser.add_argument('--version', action='version',
                        version='%(prog)s ' + VERSION)
    parser.add_argument('--user', dest='user', default=None,
                        help='Username to use to login')
    parser.add_argument('--test', dest='test', action='store_true',
                        help=argparse.SUPPRESS)

    subparsers = parser.add_subparsers(title='subcommands',
                                       description='valid actions that can be taken',
                                       help="Command for fsurf")
    # create subparser for list action
    list_parser = subparsers.add_parser('list',
                                        help='List workflows submitted in the '
                                             'last week')
    list_parser.add_argument('--all-workflows',
                             dest='all_workflows',
                             action='store_true',
                             help='List all workflows (instead of just '
                                  'those in the last week)')
    list_parser.add_argument('--user', dest='user', default=None,
                             help='Username to use to login')
    list_parser.set_defaults(func=list_workflows)

    # create subparser for status action
    status_parser = subparsers.add_parser('status',
                                          help='Get status for specified '
                                               'workflow')
    status_parser.add_argument('--id',
                               dest='workflow_id',
                               action='store',
                               type=int,
                               required=True,
                               help='ID for workflow to show')
    status_parser.add_argument('--user', dest='user', default=None,
                               help='Username to use to login')
    status_parser.set_defaults(func=get_status)

    # create subparser for remove action
    remove_parser = subparsers.add_parser('remove',
                                          help='Remove specified workflow')
    remove_parser.add_argument('--id',
                               dest='workflow_id',
                               type=int,
                               required=True,
                               action='store',
                               help='ID for workflow to remove')
    remove_parser.add_argument('--user', dest='user', default=None,
                               help='Username to use to login')
    remove_parser.set_defaults(func=remove_workflow)

    # create subparser for retry action
    retry_parser = subparsers.add_parser('retry',
                                         help='Retry a specified failed '
                                              'workflow')
    retry_parser.add_argument('--id',
                              dest='workflow_id',
                              type=int,
                              required=True,
                              action='store',
                              help='ID for workflow to retry')
    retry_parser.add_argument('--user', dest='user', default=None,
                              help='Username to use to login')
    retry_parser.set_defaults(func=retry_workflow)

    # create subparser for output action
    output_parser = subparsers.add_parser('output',
                                          help='Get output for specified '
                                               'workflow')
    output_parser.add_argument('--id',
                               dest='workflow_id',
                               action='store',
                               type=int,
                               required=True,
                               help='ID for workflow to get output for')
    output_parser.add_argument('--log-only',
                               dest='log_only',
                               action='store_true',
                               help="Only retrieve log file")
    output_parser.add_argument('--user', dest='user', default=None,
                               help='Username to use to login')
    output_parser.set_defaults(func=get_output)

    # create subparser for change password action
    change_parser = subparsers.add_parser('change-password',
                                          help='Change user password')
    change_parser.add_argument('--user', dest='user', default=None,
                               help='Username to use to login')
    change_parser.set_defaults(func=change_password)

    # create subparser for submit action
    submit_parser = subparsers.add_parser('submit',
                                          help='Submit a workflow for '
                                               'processing')
    submit_parser.add_argument('--subject',
                               dest='subject',
                               default=None,
                               help='Subject id to process ')
    submit_parser.add_argument('--dualcore',
                               dest='dualcore',
                               action='store_false',
                               default=False,
                               help='Use 2 cores to process all steps')
    submit_parser.add_argument('--deidentified',
                               dest="deidentified",
                               action="store_true",
                               help=argparse.SUPPRESS)
    submit_parser.add_argument('--defaced',
                               dest="defaced",
                               action="store_true",
                               help=argparse.SUPPRESS)
    submit_parser.add_argument('--input',
                               dest='input_file',
                               action='append',
                               default=[],
                               help='path to input file(s), this can be used '
                                    'multiple times')
    submit_parser.add_argument('--freesurfer-options',
                               dest='options',
                               default=None,
                               help='options to pass to FreeSurfer')
    submit_parser.add_argument('--version',
                               dest='version',
                               default='5.3.0',
                               help='version of FreeSurfer to use')
    submit_parser.set_defaults(func=submit_workflow)
    args = parser.parse_args(sys.argv[1:])
    if args.test:
        global REST_ENDPOINT
        REST_ENDPOINT += "_test"
    args.func(args)

if __name__ == '__main__':
    main()